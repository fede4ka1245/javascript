from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import json

EMOTION_LABELS = {
    0: "",
    1: "üòÉ",
    2: "üò≠",
    3: "ü§¨ ",
    4: "ü§î",
    5: "üò≤",
    6: "ü§Æ",
    7: "üò®",
    8: "üòñ",
    9: "ü§¶üèø‚Äç‚ôÇÔ∏è",
}

device = "cuda" if torch.cuda.is_available() else "cpu"


# –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –ª–∏ –∫–ª–∏–ø, —á—Ç–æ–±—ã —ç—Ç–æ –æ—Ç–¥–µ–ª—å–Ω–æ –≤—ã–¥–µ–ª–∏—Ç—å
@torch.no_grad()
def predict_emotion(text: str, confidence: float) -> str:
    inputs = emotion_tokenizer(
        text, max_length=512, padding=True, truncation=True, return_tensors="pt"
    ).to(device)
    outputs = emotion_model(**inputs)
    predicted = torch.nn.functional.softmax(outputs.logits, dim=1)

    if torch.max(predicted, dim=1)[0] < confidence:
        predicted = [0]
    else:
        predicted = torch.argmax(predicted, dim=1).cpu().numpy()

    return EMOTION_LABELS[predicted[0]]


# –ø–æ–ª—É—á–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–µ —ç–º–æ–¥–∂–∏
def get_emotion(text):
    EMOTION_MODEL = "Djacon/rubert-tiny2-russian-emotion-detection"

    emotion_tokenizer = AutoTokenizer.from_pretrained(EMOTION_MODEL, device_map=device)
    emotion_model = AutoModelForSequenceClassification.from_pretrained(
        EMOTION_MODEL, device_map=device
    )

    emotion = predict_emotion(text, confidence=0.6)

    return emotion


def get_interpretation(text, video_path):
    interpretation = []
    
    # —á–∞—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤–∏–¥–µ–æ –ª–µ–∂–∏—Ç –≤ –¥–∞–Ω–Ω–æ–º json —Ñ–∞–π–ª–µ
    with open("viral_video_stats.json") as f:
        current_part_info = json.load(f)[video_path]
    
    # –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª–∏–ø –Ω–∞ —ç–º–æ—Ü–∏–∏
    emotion = get_emotion(text)
    if emotion != "":
        interpretation.append(f"–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –≤–∏–¥–µ–æ. –ì–ª–∞–≤–Ω–∞—è —ç–º–æ—Ü–∏—è - {emotion}")
    
    # –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ª–∏—Ü–∞ –≤ –≤–∏–¥–µ–æ, —á—Ç–æ–±—ã –≤—ã–¥–µ–ª–∏—Ç—å —ç—Ç–æ –æ—Ç–¥–µ–ª—å–Ω–æ
    if current_path_info["is_face_detected"]:
        interpretation.append(f"–ù–∞ –≤–∏–¥–µ–æ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –ª–∏—Ü–∞")
        
    # –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—Å–∫–æ–ª—å–∫–æ –≥—Ä–æ—Å–∫–æ–µ –≤–∏–¥–µ–æ, —á—Ç–æ–±—ã –æ—Ç–µ–¥–µ–ª—å–Ω–æ —ç—Ç–æ –∫–∞–∫-—Ç–æ –≤—ã–¥–µ–ª–∏—Ç—å
    if current_path_info["percentage_of_loud"] > 80:
        interpretation.append(f"–ê—É–¥–∏–æ –≤ –∫–ª–∏–ø–µ –≥—Ä–æ–º–∫–æ–µ")
    
    # —Ç–∏—à–∏–Ω–∞ —Ç–æ–∂–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–º –≤–∏—Ä–∞–ª—å–Ω–æ—Å—Ç–∏, —Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞ –Ω–µ–π —Ç–æ–∂–µ –Ω–∞–¥–æ
    if current_path_info["percentage_of_loud"] < 10:
        interpretation.append(f"–ê—É–¥–∏–æ –≤ –∫–ª–∏–ø–µ —Ç–∏—Ö–æ–µ")
    
    return interpretation
        
