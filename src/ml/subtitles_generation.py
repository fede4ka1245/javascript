import whisper
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import re
from copy import copy

WHISPER_MODEL = "medium"

# Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð½Ð¸Ñ ÑÐ¼Ð¾Ñ†Ð¸Ð¸ Ñ‚ÐµÐºÑÑ‚Ð°
EMOTION_MODEL = "Djacon/rubert-tiny2-russian-emotion-detection"

EMOTION_LABELS = {
    0: "",
    1: "ðŸ˜ƒ",
    2: "ðŸ˜­",
    3: "ðŸ¤¬ ",
    4: "ðŸ¤”",
    5: "ðŸ˜²",
    6: "ðŸ¤®",
    7: "ðŸ˜¨",
    8: "ðŸ˜–",
    9: "ðŸ¤¦ðŸ¿â€â™‚ï¸",
}

device = "cuda" if torch.cuda.is_available() else "cpu"

whisper_model = whisper.load_model(WHISPER_MODEL, device=device)
emotion_tokenizer = AutoTokenizer.from_pretrained(EMOTION_MODEL, device_map=device)
emotion_model = AutoModelForSequenceClassification.from_pretrained(
    EMOTION_MODEL, device_map=device
)


@torch.no_grad()
def predict_emotion(text: str, confidence: float) -> str:
    inputs = emotion_tokenizer(
        text, max_length=512, padding=True, truncation=True, return_tensors="pt"
    ).to(device)
    outputs = emotion_model(**inputs)
    predicted = torch.nn.functional.softmax(outputs.logits, dim=1)

    if torch.max(predicted, dim=1)[0] < confidence:
        predicted = [0]
    else:
        predicted = torch.argmax(predicted, dim=1).cpu().numpy()

    return EMOTION_LABELS[predicted[0]]


def split_text_by_sentences(text: str) -> list[str]:
    return re.findall(r"[^.!?]+[.!?]", text)


def get_timestamps_words_array(segments: list[dict]) -> list[dict]:
    result = []

    for segment in segments:
        for word in segment["words"]:
            result.append(
                {"word": word["word"], "start": word["start"], "end": word["end"], "length": len(word["word"])}
            )

    return result


# Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð±Ð¸Ñ€ÑƒÐµÐ¼ Ñ‚ÐµÐºÑÑ‚ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ openai-whisper, Ð²Ñ‹Ð´ÐµÐ»ÑÐµÐ¼ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ñ‹ Ð´Ð»Ñ Ð¾Ð±Ð¾Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ ÑÐ¼Ð¾Ñ†Ð¸Ð¹ Ð¸ ÑÐ»Ð¾Ð²Ð° Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾ Ñ timestamp, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð²ÑÑ‚Ð°Ð²Ð»ÑÑ‚ÑŒ Ð¸Ñ… Ñ‚Ð¸Ñ‚Ñ€Ð°Ð¼Ð¸ Ð² Ð²Ð¸Ð´ÐµÐ¾ Ð² ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ð¸ Ñ Ñ‚Ð°Ð¹Ð¼Ð¸Ð½Ð³Ð°Ð¼Ð¸
def get_transcribed_text(path_to_file: str) -> (str, list[dict]):
    result = whisper_model.transcribe(word_timestamps=True, audio=path_to_file)
    text = result["text"]
    segments = [
        {
            "text": segment["text"],
            "start": segment["start"],
            "end": segment["end"],
            "length": len(segment["text"]),
            "words": segment["words"],
        }
        for segment in result["segments"]
    ]
    timestamps_words = get_timestamps_words_array(segments)

    return text, segments, timestamps_words


# Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼ Ð´Ð»Ñ Ð²ÑÑ‚Ð°Ð²ÐºÐ¸ ÑÐ¼Ð¾Ð´Ð¶Ð¸ Ð² ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ñ‹
def update_segments(segments: list[dict], emoji_positions: list[int], emojies: list[str], text_def="text") -> list[dict]:
    current_pos = 0
    
    print(emoji_positions, emojies)

    for segment in segments:
        if not emojies:
            return segments

        while emoji_positions[0] < current_pos + segment["length"]:
            segment["length"] += 1
            segment[text_def] = segment[text_def][:emoji_positions[0] - current_pos] + emojies[0] + segment[text_def][emoji_positions[0] - current_pos:]
            emojies.pop(0)
            emoji_positions.pop(0)
            
            if not emojies:
                return segments

        current_pos += segment["length"]

    return segments


# Ð²ÑÑ‚Ð°Ð²Ð»ÑÐµÐ¼ ÑÐ¼Ð¾Ð´Ð¶Ð¸ Ð² Ñ‚ÐµÐºÑÑ‚ Ð¿Ð¾ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ñƒ
def insert_emojies(
    splitted_text: list[str], context_sentences: int = 2, confidence: float = 0.7
) -> (str, list[int], list[str]):
    current_pos = 0
    emoji_positions = []
    emojies = []
    text_with_emojies = ""

    for i, sentence in enumerate(splitted_text):
        emoji = predict_emotion(
            "".join(splitted_text[max(0, i - 2) : i + 1]), confidence=confidence
        )

        if emoji != "":
            emoji_positions.append(current_pos + len(sentence) - 1)
            emojies.append(emoji)

        current_pos += len(sentence) + len(emoji)
        text_with_emojies += sentence[:-1] + emoji + sentence[-1]

    return text_with_emojies, emoji_positions, emojies


def inference(path_to_file: str) -> dict:
    transcribed_text, segments, timestamps_words = get_transcribed_text(path_to_file)
    splitted_text = split_text_by_sentences(transcribed_text)
    raw_text, emoji_positions, emojies = insert_emojies(splitted_text)
    segments = update_segments(segments, copy(emoji_positions), copy(emojies))
    timestamps_words = update_segments(timestamps_words, copy(emoji_positions), copy(emojies), text_def="word")
    return {"text": raw_text, "segments": segments, "words": timestamps_words}